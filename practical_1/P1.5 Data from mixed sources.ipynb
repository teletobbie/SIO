{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow a similar process in this step, only now the data set comes from different sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load a data set that integrates the data we have from the different sources. cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/mixed_data.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is available on Nestor.\n",
    "\n",
    "We start our exploratory analysis by inspecting the size of the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this file has 30000 records and 26 fields (columns). Note that this is one more column than before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Check Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the data set contains monthly credit card account data, for a period of six months. Let's perform a quality check to ensure we have the data for the accounts as expected. The account ID distinguishes one account from the other. We can check unique IDs with Pandas with the function `.nunique()`. But first let's check our data structure. To do so we first build an Index of he different columns in the table. We will use the .columns method of the pandas DataFrame to see the column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'DOB',\n",
       "       'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',\n",
       "       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
       "       'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default payment next month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see the heading for the additional column?\n",
    "\n",
    "This is the DOB column. \n",
    "\n",
    "\n",
    "We then check the column headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b15e78fe-a223</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6420</td>\n",
       "      <td>49240</td>\n",
       "      <td>6772</td>\n",
       "      <td>31305</td>\n",
       "      <td>43864</td>\n",
       "      <td>6453</td>\n",
       "      <td>49470</td>\n",
       "      <td>3723</td>\n",
       "      <td>103686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>689ae71c-3f4b</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1170</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>1170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3dc1d96e-35c2</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1981-10-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31240</td>\n",
       "      <td>20343</td>\n",
       "      <td>12349</td>\n",
       "      <td>2017</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3007</td>\n",
       "      <td>1003</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f786754a-eb0b</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1982-10-22</td>\n",
       "      <td>Not available</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1961</td>\n",
       "      <td>1261</td>\n",
       "      <td>2681</td>\n",
       "      <td>13196</td>\n",
       "      <td>2866</td>\n",
       "      <td>1961</td>\n",
       "      <td>1261</td>\n",
       "      <td>2681</td>\n",
       "      <td>1261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6a3c5a6-7647</td>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE        DOB  \\\n",
       "0  b15e78fe-a223     500000    1          1         1   42 1900-01-01   \n",
       "1  689ae71c-3f4b      30000    1          2         1   36 1900-01-01   \n",
       "2  3dc1d96e-35c2      50000    1          1         1    0 1981-10-21   \n",
       "3  f786754a-eb0b      50000    1          3         1    0 1982-10-22   \n",
       "4  e6a3c5a6-7647     200000    2          1         2   36 1900-01-01   \n",
       "\n",
       "           PAY_1  PAY_2  PAY_3  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "0             -2     -1      0  ...       6420      49240       6772   \n",
       "1              1     -1     -1  ...       1170        780          0   \n",
       "2              0      0      0  ...      31240      20343      12349   \n",
       "3  Not available     -1     -1  ...       1961       1261       2681   \n",
       "4             -2     -2     -2  ...          0          0          0   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0     31305     43864      6453     49470      3723    103686   \n",
       "1       780         0      1170         0         0         0   \n",
       "2      2017      3000      2000      3007      1003      1500   \n",
       "3     13196      2866      1961      1261      2681      1261   \n",
       "4         0         0         0         0         0         0   \n",
       "\n",
       "   default payment next month  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see: we have a DOB column which is likely to be Date of Birth. \n",
    "Indeed we consult our sources and this is confirmed. \n",
    "But something is not quite right with the data now. We see that for some records we have the 'AGE'column, while for some other we have the \"DOB\". Additionally, do you see something additional which is not quite right?\n",
    "As our data came from different sources, one of the sources was recording the age, but for this one the DOB contains an invalid date, while the opposite happens for the other source. \n",
    "We need to do something about it. But before doing so, let's repeat our previous steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we check the unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29687"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting! We have fewer unique IDs than rows, so we clearly hae duplicates! We can check the number of occurences of each ID by counting them, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4fcef74d-0b3d    2\n",
       "a7e199e1-2c44    2\n",
       "a9ce8636-9a88    2\n",
       "d9dafe9c-b497    2\n",
       "3367c92b-b1ca    2\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts = df['ID'].value_counts()\n",
    "id_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29374\n",
       "2      313\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of records is not different than before: We have 29374 IDs which appear only once but we also hae 313 which appear twice! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Continue with Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now examine in mode detail the duplicate IDs. To do so, let's create a Boolean mask to locate the duplicate IDs. We name this 'mask dupe_mask'. Let's display the first five elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_mask = id_counts == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4fcef74d-0b3d    True\n",
       "a7e199e1-2c44    True\n",
       "a9ce8636-9a88    True\n",
       "d9dafe9c-b497    True\n",
       "3367c92b-b1ca    True\n",
       "Name: ID, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_mask[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the '5'in the command above with another number and observe a different number of records. Let's keep it '5'now and inspect the duplicate ID records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['4fcef74d-0b3d', 'a7e199e1-2c44', 'a9ce8636-9a88', 'd9dafe9c-b497',\n",
       "       '3367c92b-b1ca'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts.index[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to access and inspect these records, let's store their ID numbers in a variable named 'dupe_ids' and inspect the first 10 such records:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_ids = id_counts.index[dupe_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['4fcef74d-0b3d', 'a7e199e1-2c44', 'a9ce8636-9a88', 'd9dafe9c-b497',\n",
       "       '3367c92b-b1ca', '26d4a6eb-8abe', '98395d08-9643', '823267c1-561b',\n",
       "       '82da3aa5-97a6', '26bde6da-f148'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the cardinality of the dupe_ids variable (i.e. how many records it contains). We use 'len' for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_ids = list(dupe_ids)\n",
    "len(dupe_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right - as expected. So we focus again on the first 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4fcef74d-0b3d',\n",
       " 'a7e199e1-2c44',\n",
       " 'a9ce8636-9a88',\n",
       " 'd9dafe9c-b497',\n",
       " '3367c92b-b1ca']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_ids[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the records with the duplicate IDs, we wish to inspect their data in more detail. Is there anything different in the values of these records which have identical IDs? Our approach to do so is this: we first focus on the data records with the first 3 duplicate IDs, as a sample. First we focus on finding the rows which contain these 3 IDs. The first three IDs are dupe_ids[0:3]. \n",
    "\n",
    "We will use the '.isin' method to create another logical mask. We will pass the earlier selected list of IDs through this mask and apply this on the larger dataframe to display the rows that have this ID. We use the .loc method for locating these IDs. The '.isin' method is NESTED within the .loc statement: this indexes the datafame to select the location of all rows containing a True value in the logical mask. The : in the second argument of the loc implies that all columns will be seleted. So in this way we filter the Dataframe so as to view all the columns for the first three duplicate IDs. This is not very comlex filtering but still it is a sign of the compactness of the Python language that a single command with this nested structure produces this outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DOB</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>4fcef74d-0b3d</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-04</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>120142</td>\n",
       "      <td>60428</td>\n",
       "      <td>58192</td>\n",
       "      <td>3000</td>\n",
       "      <td>2746</td>\n",
       "      <td>0</td>\n",
       "      <td>2297</td>\n",
       "      <td>1875</td>\n",
       "      <td>1158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>a9ce8636-9a88</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10926</td>\n",
       "      <td>17536</td>\n",
       "      <td>2090</td>\n",
       "      <td>2000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>7000</td>\n",
       "      <td>2090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17714</th>\n",
       "      <td>4fcef74d-0b3d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27248</th>\n",
       "      <td>a7e199e1-2c44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28847</th>\n",
       "      <td>a7e199e1-2c44</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1990-10-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25362</td>\n",
       "      <td>26318</td>\n",
       "      <td>42484</td>\n",
       "      <td>6363</td>\n",
       "      <td>4386</td>\n",
       "      <td>5362</td>\n",
       "      <td>4344</td>\n",
       "      <td>20000</td>\n",
       "      <td>4382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29669</th>\n",
       "      <td>a9ce8636-9a88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE        DOB  \\\n",
       "1742   4fcef74d-0b3d      60000    1          2         2    0 1995-11-04   \n",
       "6396   a9ce8636-9a88      20000    2          2         1   34 1900-01-01   \n",
       "17714  4fcef74d-0b3d          0    0          0         0    0        NaT   \n",
       "27248  a7e199e1-2c44          0    0          0         0    0 1900-01-01   \n",
       "28847  a7e199e1-2c44     100000    1          2         2    0 1990-10-30   \n",
       "29669  a9ce8636-9a88          0    0          0         0    0 1900-01-01   \n",
       "\n",
       "               PAY_1  PAY_2  PAY_3  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "1742               2      2      2  ...     120142      60428      58192   \n",
       "6396   Not available      0      0  ...      10926      17536       2090   \n",
       "17714              0      0      0  ...          0          0          0   \n",
       "27248              0      0      0  ...          0          0          0   \n",
       "28847              0      0      0  ...      25362      26318      42484   \n",
       "29669              0      0      0  ...          0          0          0   \n",
       "\n",
       "       PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "1742       3000      2746         0      2297      1875      1158   \n",
       "6396       2000      3000      3000      7000      2090         0   \n",
       "17714         0         0         0         0         0         0   \n",
       "27248         0         0         0         0         0         0   \n",
       "28847      6363      4386      5362      4344     20000      4382   \n",
       "29669         0         0         0         0         0         0   \n",
       "\n",
       "       default payment next month  \n",
       "1742                            1  \n",
       "6396                            0  \n",
       "17714                           0  \n",
       "27248                           0  \n",
       "28847                           0  \n",
       "29669                           0  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['ID'].isin(dupe_ids[0:3]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets interesting. For each pair of rows with duplicate IDs, on row contains potentially valid data, but the other one only contains 0s! It is most likley that a data clearning process would be expected to delete all such eroneous data (you can't for example have an age of 0 or a credit limit of 0 and stil be part of the data processing! If we attempted to find the rows with all data values being zeros we would have failed, but if we seek to find the data records that apart from the ID value, all other variable values are 0s, this might work much better. We will use the == operator to make an asignment to a variable that will be used as a mask. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 26)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_mask = df == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wil use the df_zero_mask to check for 0 values in all other columns apart from the ID one (which we know that does have non-0 values). So we will use all axes in the 'dimensions' of the data set, apart from the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_zero_mask = df_zero_mask.iloc[:,1:].all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(feature_zero_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's no good! Now that we have data from different sources, the simple rule we had last time does not seem to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1 = df.loc[~feature_zero_mask,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 26)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29687"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_1['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are exactly where we started. We need to change approach. We first have to deal with resolving the data from the different sources ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1a153170a3f217d001d6e9df4ac4e4ab4fdaf0e0bf55a7345ffbd89e66bc90f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
